{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-06 17:08:27.550994: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-06 17:08:28.078568: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/jtfc/HS/M2aia/m2aia-dev/m2aia-release/MITK-build/lib:/home/jtfc/HS/M2aia/m2aia-dev/m2aia-release/MITK-build/lib/MitkCore:/home/jtfc/HS/M2aia/m2aia-dev/m2aia-release/MITK-build/lib:/home/jtfc/HS/M2aia/m2aia-dev/m2aia-release/MITK-build/lib/MitkCore\n",
      "2022-12-06 17:08:28.078621: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/jtfc/HS/M2aia/m2aia-dev/m2aia-release/MITK-build/lib:/home/jtfc/HS/M2aia/m2aia-dev/m2aia-release/MITK-build/lib/MitkCore:/home/jtfc/HS/M2aia/m2aia-dev/m2aia-release/MITK-build/lib:/home/jtfc/HS/M2aia/m2aia-dev/m2aia-release/MITK-build/lib/MitkCore\n",
      "2022-12-06 17:08:28.078626: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import m2aia as m2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from msiPL.Computational_Model import VAE_BN\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from Example_IV_Helpers import running_variance_update as update \n",
    "from Example_IV_Helpers import running_variance_finalize as finalize\n",
    "from Example_IV_Helpers import BatchSequence\n",
    "\n",
    "from msiPL.LearnPeaks import *\n",
    "\n",
    "from download_helper import DownloadMTBLS2639\n",
    "file_names = DownloadMTBLS2639([1,2,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Tue Dec  6 17:08:29 2022 \n",
      "5.295] [imzML]: data/150429_ew_section1_pos.imzML\n",
      "\t[pixel size]: 25.000000x25.000000\n",
      "\t[image area]: 206x107\n",
      "\t[image dims]: 5150.000000x2675.000000\n",
      "[7.278] [imzML]: data/150429_ew_section2_pos.imzML\n",
      "\t[pixel size]: 25.000000x25.000000\n",
      "\t[image area]: 220x171\n",
      "\t[image dims]: 5500.000000x4275.000000\n",
      "[10.329] [imzML]: data/150505_ew_section3_pos.imzML\n",
      "\t[pixel size]: 25.000000x25.000000\n",
      "\t[image area]: 224x169\n",
      "\t[image dims]: 5600.000000x4225.000000\n",
      "[13.552] [imzML]: data/150417_ew_section4_pos.imzML\n",
      "\t[pixel size]: 25.000000x25.000000\n",
      "\t[image area]: 197x192\n",
      "\t[image dims]: 4925.000000x4800.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-06 17:08:30.390161: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-06 17:08:30.509513: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-06 17:08:30.509840: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-06 17:08:30.510943: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-06 17:08:30.511879: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-06 17:08:30.512163: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-06 17:08:30.512404: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-06 17:08:30.916338: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-06 17:08:30.916783: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-06 17:08:30.916956: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-06 17:08:30.917103: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21554 MB memory:  -> device: 0, name: NVIDIA TITAN RTX, pci bus id: 0000:07:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/501]\n",
      "[3, 3, 3, 3]\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-06 17:08:34.306189: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x237f62c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2022-12-06 17:08:34.306216: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA TITAN RTX, Compute Capability 7.5\n",
      "2022-12-06 17:08:34.321645: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2022-12-06 17:08:34.435640: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-12-06 17:08:34.515109: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "779/779 [==============================] - 28s 32ms/step - loss: 8042.4692770, 770, 771]]] 6, 5][7, 7, 8, 8][10, 10, 9, 10][11, 12, 12, 12][13, 14, 14, 14][16, 16, 16, 15][17, 18, 18, 17][20, 20, 19, 20][22, 22, 22, 21][24, 23, 24, 23[26, 26, 25, 25][28, 28, 27, 27][29, 30, 30, 29][31, 32, 32, 32][34, 34, 34, 33][36, 36, 36, 35][38, 38, 38, 37][39, 40, 40, 39][42, 42, 41, 42][43, 43, 44, 44][46, 46, 46, 45][48, 48, 48, 47][49, 50, 50, 50][51, 52, 52, 52][54, 54, 54, 53][55, 56, 56, 56][58, 58, 58, 57][59, 60, 59, 60][62, 62, 61, 62][63, 64, 64, 64][65, 66, 66, 66][67, 68, 68, 68][70, 70, 70, 69][72, 72, 72, 71][73, 74, 74, 74][76, 75, 76, 76][78, 78, 78, 77][82, 82, 82, 81][84, 84, 83, 84][86, 86, 86, 85][88, 88, 88, 87][91, 92, 92, 92[96, 96, 96, 95][97, 98, 98, 98][99, 100, 100, 100][102, 102, 101, 102][104, 103, 104, 104][106, 106, 105, 106][108, 107, 107, 108][110, 109, 110, 110][112, 111, 112, 112][113, 114, 114, 114][116, 116, 116, 115][120, 119, 120, 120][122, 121, 122, 122[124, 124, 124, 123][126, 125, 126, 126][128, 128, 128, 128][129, 130, 130, 130[132, 131, 132, 132][133, 134, 134, 134[135, 136, 136, 136][138, 138, 137, 138][139, 140, 140, 140][142, 142, 142, 141][144, 144, 143, 144][145, 146, 146, 146][147, 148, 148, 148][150, 150, 149, 150][151, 152, 152, 152][155, 156, 156, 156][158, 158, 158, 157][159, 159, 160, 160][161, 162, 162, 162][164, 164, 164, 163[166, 165, 166, 166][168, 168, 168, 167][170, 170, 170, 169][172, 172, 172, 171][174, 173, 174, 174][176, 176, 175, 176][178, 178, 178, 177[180, 180, 180, 179][182, 181, 182, 182][183, 184, 184, 183][186, 186, 186, 185][188, 187, 188, 188][189, 190, 190, 190[191, 191, 192, 192][194, 194, 194, 193][195, 196, 196, 196][197, 198, 198, 198][200, 200, 200, 199][201, 202, 202, 201][204, 203, 204, 204][206, 205, 206, 206][207, 208, 208, 208[209, 210, 209, 210][211, 212, 212, 212][214, 214, 213, 214][216, 216, 216, 215][218, 217, 218, 218][219, 220, 220, 220][221, 222, 222, 222[223, 223, 224, 224][226, 225, 226, 226][228, 228, 228, 227][229, 230, 230, 230][232, 232, 231, 232][233, 234, 234, 234[236, 236, 235, 236[238, 237, 238, 238[240, 240, 239, 240][241, 242, 242, 242][243, 244, 244, 244][245, 246, 246, 246][248, 247, 248, 248][249, 250, 250, 250][252, 252, 252, 251][253, 254, 254, 254][256, 256, 255, 256][257, 258, 257, 258][260, 260, 259, 260][262, 262, 262, 261][264, 264, 263, 264][266, 265, 266, 266[267, 268, 267, 268[269, 270, 269, 270][271, 272, 272, 272][273, 274, 274, 274[276, 275, 276, 276][277, 278, 278, 278][280, 280, 280, 279][282, 282, 282, 281][284, 283, 284, 284][285, 286, 286, 286][287, 288, 287, 288][290, 290, 289, 290[292, 291, 292, 292][293, 294, 294, 294[296, 295, 296, 296][298, 298, 298, 297][299, 300, 300, 300][302, 301, 301, 302][303, 304, 304, 304][306, 305, 306, 306[308, 307, 308, 308][310, 310, 310, 309][312, 311, 312, 312][314, 313, 314, 314][316, 316, 316, 315][318, 318, 318, 317][322, 321, 322, 322][323, 324, 324, 324][325, 326, 326, 326][328, 328, 327, 328][330, 329, 330, 330][332, 332, 332, 331][334, 334, 334, 333][336, 336, 335, 336][337, 338, 338, 337][342, 341, 342, 342][344, 344, 344, 343][346, 346, 346, 345[348, 347, 348, 348][351, 352, 352, 352][354, 354, 353, 354[356, 355, 355, 356][357, 358, 358, 358[362, 362, 361, 362][363, 364, 364, 364][366, 365, 366, 366[367, 368, 367, 368][369, 370, 370, 370[371, 372, 372, 371][374, 374, 373, 374][375, 376, 376, 376][377, 378, 378, 378][379, 380, 380, 380][381, 382, 382, 382][384, 384, 383, 384[386, 385, 386, 386][387, 387, 388, 388][389, 390, 390, 390][392, 391, 392, 392[394, 394, 393, 394][395, 396, 395, 396][400, 400, 399, 400][402, 401, 402, 401][404, 404, 403, 404][405, 405, 406, 406][408, 407, 408, 408][410, 409, 410, 410][412, 412, 412, 411][414, 414, 413, 414[416, 415, 416, 416][418, 417, 418, 418][420, 419, 420, 420][421, 422, 422, 422][423, 424, 424, 424][425, 426, 426, 426][428, 427, 428, 428][429, 430, 430, 430[431, 432, 432, 432][433, 434, 434, 434][435, 436, 435, 436][437, 438, 438, 438][439, 440, 439, 440][441, 442, 442, 442][443, 443, 444, 444][446, 446, 445, 446][447, 448, 448, 448][450, 449, 450, 450[452, 452, 451, 452][454, 453, 454, 454][456, 456, 456, 455][457, 458, 457, 458][460, 460, 459, 460][462, 462, 461, 462][463, 464, 464, 464][465, 466, 466, 465][467, 468, 468, 468][469, 470, 470, 470][472, 472, 472, 472][473, 474, 474, 474][476, 475, 476, 476][478, 478, 478, 477][480, 480, 480, 479][481, 482, 482, 482][483, 484, 483, 484][486, 486, 485, 486][487, 488, 488, 488][490, 490, 489, 490][492, 492, 491, 492][493, 494, 494, 493][495, 495, 496, 496][500, 500, 499, 500][502, 501, 502, 502][504, 504, 503, 504][506, 506, 505, 506][507, 508, 508, 508][510, 510, 510, 509][511, 512, 512, 512][514, 514, 514, 513][516, 515, 516, 516][518, 518, 518, 517][520, 520, 519, 520][522, 522, 521, 522][523, 524, 524, 524][525, 526, 526, 525][528, 527, 528, 528[529, 529, 530, 530][532, 532, 531, 532][533, 534, 534, 534][535, 536, 536, 536[539, 540, 540, 540][541, 542, 542, 542][543, 544, 543, 544][545, 546, 546, 546][547, 548, 548, 548][550, 549, 550, 550][554, 553, 554, 554[556, 556, 556, 555][558, 558, 558, 557[560, 559, 560, 559][562, 562, 561, 56[566, 566, 566, 565][568, 567, 568, 568][570, 570, 569, 570][571, 572, 572, 572][574, 573, 574, 574][575, 575, 576, 576][577, 578, 578, 578][580, 579, 580, 580][582, 582, 581, 582[586, 586, 586, 585][588, 587, 588, 588][590, 590, 590, 589][591, 592, 592, 592][593, 594, 594, 594][596, 596, 596, 595][597, 598, 598, 597][600, 599, 600, 600][602, 601, 602, 602][603, 604, 604, 604][606, 605, 606, 606][607, 608, 608, 608][610, 610, 610, 609][611, 612, 612, 611][614, 614, 614, 613][615, 616, 616, 616][618, 618, 617, 618][619, 620, 620, 620][621, 622, 622, 621][623, 624, 623, 624][625, 626, 626, 626][627, 628, 628, 628[630, 630, 630, 629][631, 632, 632, 632][633, 634, 634, 634][635, 636, 636, 636][638, 638, 638, 637[640, 639, 640, 640[642, 642, 642, 641[644, 643, 644, 644][645, 646, 646, 646][647, 648, 648, 648[650, 650, 650, 649][651, 652, 652, 652][654, 654, 654, 653][656, 656, 655, 656][657, 658, 658, 658][660, 660, 659, 660][662, 661, 662, 662][663, 664, 664, 664][668, 667, 668, 668][669, 670, 670, 670][672, 672, 672, 671][674, 673, 674, 674][676, 676, 675, 676][677, 678, 678, 677][679, 680, 680, 680][681, 682, 682, 682][686, 685, 686, 686][688, 688, 687, 688][689, 690, 689, 690][691, 692, 692, 69[695, 695, 695, 694][696, 697, 697, 697][699, 699, 698, 699][701, 700, 701, 701][703, 702, 703, 703][704, 705, 705, 705][707, 706, 707, 706][709, 709, 709, 708][710, 711, 711, 711][713, 712, 713, 713][714, 714, 715, 715][717, 717, 717, 716][718, 719, 719, 719][720, 721, 721, 721][722, 723, 723, 723[724, 724, 725, 725[727, 727, 727, 726][728, 728, 729, 729][731, 731, 731, 730[732, 733, 733, 733][735, 735, 734, 734][736, 737, 736, 737][739, 738, 739, 739][741, 741, 741, 740][743, 742, 743, 743[744, 745, 745, 744][747, 746, 746, 747[748, 747, 747, 748][749, 750, 750, 750][751, 752, 752, 752][753, 754, 754, 754][756, 756, 756, 755][757, 758, 758, 757][759, 760, 760, 760][762, 762, 761, 762][763, 764, 763, 764][765, 765, 764, 765[768, 769, 768, 769][772, 771, 772, 772][774, 773, 774, 774[775, 776, 775, 776][777, 777, 778, 7\n",
      "Epoch 2/50\n",
      "779/779 [==============================] - 15s 19ms/step - loss: 3163.7327\n",
      "Epoch 3/50\n",
      "779/779 [==============================] - 14s 18ms/step - loss: 2330.7747\n",
      "Epoch 4/50\n",
      "779/779 [==============================] - 16s 20ms/step - loss: 1963.7784\n",
      "Epoch 5/50\n",
      "779/779 [==============================] - 16s 20ms/step - loss: 1785.2087\n",
      "Epoch 6/50\n",
      "779/779 [==============================] - 15s 19ms/step - loss: 1657.8466\n",
      "Epoch 7/50\n",
      "779/779 [==============================] - 14s 18ms/step - loss: 1569.1393\n",
      "Epoch 8/50\n",
      "779/779 [==============================] - 14s 18ms/step - loss: 1512.2275\n",
      "Epoch 9/50\n",
      "779/779 [==============================] - 14s 18ms/step - loss: 1476.5649\n",
      "Epoch 10/50\n",
      "779/779 [==============================] - 14s 18ms/step - loss: 1419.3906\n",
      "Epoch 11/50\n",
      "779/779 [==============================] - 13s 17ms/step - loss: 1406.6815\n",
      "Epoch 12/50\n",
      "779/779 [==============================] - 14s 18ms/step - loss: 1380.3816\n",
      "Epoch 13/50\n",
      "779/779 [==============================] - 14s 18ms/step - loss: 1353.9180\n",
      "Epoch 14/50\n",
      "779/779 [==============================] - 14s 18ms/step - loss: 1325.0233\n",
      "Epoch 15/50\n",
      "779/779 [==============================] - 14s 18ms/step - loss: 1324.4557\n",
      "Epoch 16/50\n",
      "779/779 [==============================] - 15s 19ms/step - loss: 1300.0280\n",
      "Epoch 17/50\n",
      "779/779 [==============================] - 15s 19ms/step - loss: 1302.9752\n",
      "Epoch 18/50\n",
      "779/779 [==============================] - 15s 19ms/step - loss: 1286.5616\n",
      "Epoch 19/50\n",
      "276/779 [=========>....................] - ETA: 9s - loss: 1268.9969"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "latent_dim = 5\n",
    "interim_dim = 256\n",
    "epochs = 50\n",
    "batch_size = 128\n",
    "\n",
    "models = None\n",
    "handles = []\n",
    "# READ DATA\n",
    "for f in file_names:\n",
    "\n",
    "    I = m2.ImzMLReader(f)\n",
    "    I.Execute()\n",
    "    handles.append(I)\n",
    "\n",
    "vae = VAE_BN(I.GetXAxisDepth(), interim_dim, latent_dim)\n",
    "myModel, encoder = vae.get_architecture()\n",
    "\n",
    "f_name = Path(f).name\n",
    "if os.path.exists(f'models/Example_IV_B_{interim_dim}_{f_name}_multiple.h5'):\n",
    "    # ============= Load Model =================\n",
    "    myModel.load_weights(f'models/Example_IV_B_{interim_dim}_{f_name}_multiple.h5')\n",
    "else:\n",
    "    # ============= Model Training =================\n",
    "    dataset = m2.Dataset.SpectrumDataset(handles)\n",
    "    gen = BatchSequence(dataset, batch_size=batch_size, shuffle=True)\n",
    "    history = myModel.fit(gen, epochs=epochs)\n",
    "    myModel.save_weights(f'models/Example_IV_B_{interim_dim}_{f_name}_multiple.h5')\n",
    "\n",
    "models = [myModel, encoder]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learned_peaks = []\n",
    "Beta = 1.3\n",
    "for k, I in enumerate(handles):   \n",
    "    I : m2.ImzMLReader = I\n",
    "\n",
    "    count = 0\n",
    "    mean = np.zeros_like(I.GetXAxis())\n",
    "    deltaM2  = np.zeros_like(I.GetXAxis())\n",
    "    existingAggregate = (count, mean, deltaM2)\n",
    "\n",
    "    for i in range(I.GetNumberOfSpectra()):\n",
    "        xs, ys = I.GetSpectrum(i)\n",
    "        existingAggregate = update(existingAggregate, ys)\n",
    "        \n",
    "_, var, _ = finalize(existingAggregate)\n",
    "W_enc = models[1].get_weights()\n",
    "_, _, _, Real_PeakIdx = LearnPeaks(I.GetXAxis(), W_enc, np.sqrt(var), latent_dim,Beta, I.GetMeanSpectrum())\n",
    "learned_peaks.append(Real_PeakIdx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_orig_spectra = []\n",
    "mean_recon_spectra = []\n",
    "for i, I in enumerate(handles):\n",
    "    dataset = m2.Dataset.SpectrumDataset([I])\n",
    "    gen = m2.BatchGenerator(dataset, batch_size=I.GetNumberOfSpectra(), shuffle=True)\n",
    "    X = gen[0]\n",
    "    R = models[0].predict(X)\n",
    "    mean_orig_spectra.append(np.mean(X,axis=0))\n",
    "    mean_recon_spectra.append(np.mean(R,axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save(\"IV_B.np\", mean_recon_spectra)\n",
    "# np.save(\"learned_peaks\", learned_peaks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = I.GetXAxis()\n",
    "colors = ['r{}','g{}','b{}','y{}']\n",
    "labels = []\n",
    "ytick = []\n",
    "yhlines = []\n",
    "ytick_label = []\n",
    "scale_factor = 0.7\n",
    "fraction_of_max = 0.05\n",
    "stretch_factor = 1\n",
    "plt.figure(figsize=(16,9))\n",
    "for i, _ in enumerate(handles):\n",
    "    ytick.append(-i*stretch_factor)\n",
    "    yhlines.append(-i*stretch_factor-0.15)\n",
    "    ytick.append(((-i*stretch_factor)+(-i*stretch_factor+scale_factor))*0.5)\n",
    "    ytick.append(-i*stretch_factor+scale_factor)\n",
    "    ytick_label.append('')\n",
    "    ytick_label.append(f'Slice {i+1}')\n",
    "    ytick_label.append(f'{int(fraction_of_max*100)}%')\n",
    "    err = np.abs(mean_orig_spectra[i]-mean_recon_spectra[i])\n",
    "    plt.plot(xs, np.clip(mean_orig_spectra[i]/(np.max(mean_orig_spectra[i])*fraction_of_max),0,1)*0.7 - (i*stretch_factor),  color='#facd60')\n",
    "    plt.plot(xs, np.clip(mean_recon_spectra[i]/(np.max(mean_orig_spectra[i])*fraction_of_max),0,1)*0.7 - (i*stretch_factor), color='k', alpha=0.7, linestyle=(0, (4, 4)))\n",
    "    plt.plot(xs, err/(np.max(mean_orig_spectra)*fraction_of_max) - (i*stretch_factor), color='#e74645')\n",
    "\n",
    "    plt.plot(xs[learned_peaks[0]], [-(i*stretch_factor)-0.05 for _ in learned_peaks[0]], '^', color='b')\n",
    "\n",
    "labels.append(f'Original mean spectrum')\n",
    "labels.append(f'Reconstructed mean spectrum')\n",
    "labels.append(f'Absolute error')\n",
    "labels.append(f'Identified peaks')\n",
    "plt.hlines(ytick[2::3],200,270, colors='gray', label=[f'Section {l+1}' for l in range(4)], linestyles='dotted')\n",
    "plt.legend(labels=labels, fontsize='large', bbox_to_anchor=(0.375,-0.25), loc=\"center left\")\n",
    "plt.xlabel('m/z')\n",
    "plt.ylabel('Normalized intensity/error')\n",
    "plt.yticks(ytick, ytick_label)\n",
    "plt.xlim([220, 240])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======== Visualize encoded Features (learned non-linear spectral manifold) ==========\n",
    "\n",
    "ims = []\n",
    "height = 0\n",
    "width = 0\n",
    "x_dims = []\n",
    "y_dims = []\n",
    "\n",
    "for j, I in enumerate(handles):\n",
    "    \n",
    "    x_dim, y_dim, z_dim = I.GetShape()\n",
    "    print(x_dim, y_dim, z_dim)\n",
    "    im = np.zeros((latent_dim, y_dim, x_dim))\n",
    "    x_dims.append(x_dim)\n",
    "    y_dims.append(y_dim)\n",
    "\n",
    "    dataset = m2.Dataset.SpectrumDataset([I])\n",
    "    gen = m2.BatchGenerator(dataset, batch_size=I.GetNumberOfSpectra(), shuffle=False)\n",
    "    _, _, c = models[1].predict(gen[0])\n",
    "    \n",
    "    for id in range(I.GetNumberOfSpectra()):\n",
    "        x,y,z = I.GetSpectrumPosition(id)\n",
    "        im[:, y, x] = c[id,:]\n",
    "    \n",
    "    # for ll in range(latent_dim):\n",
    "    #     im[ll, y, x] = im[ll, y, x] - np.mean(im[ll, y, x])\n",
    "    #     im[ll, y, x] = im[ll, y, x] / np.std(im[ll, y, x])\n",
    "        \n",
    "\n",
    "    ims.append(im)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import seaborn_image as seaim\n",
    "sns.set_theme(style=\"darkgrid\")\n",
    "sns.set(rc={'figure.figsize':(19,6)})\n",
    "\n",
    "height = np.sum(y_dims)\n",
    "max_im_width = np.max(x_dims)\n",
    "width = max_im_width * latent_dim\n",
    "\n",
    "im_final = np.zeros((height, width))\n",
    "\n",
    "\n",
    "y_pos = 0\n",
    "for i, ims_temp in enumerate(ims):\n",
    "    d,h,w = ims_temp.shape\n",
    "    # print(h,w)\n",
    "    min = np.min(ims_temp)\n",
    "    max = np.max(ims_temp)\n",
    "    x_pos = 0\n",
    "    for k in range(latent_dim):\n",
    "        # print(y_pos,y_pos+h, x_pos,x_pos+w)\n",
    "        \n",
    "        rescaled = np.copy(ims_temp[k])\n",
    "        mask = rescaled!=0\n",
    "        # rescaled[mask] = rescaled[mask] - np.mean(rescaled[mask])\n",
    "        # rescaled[mask] = rescaled[mask] / np.max(np.abs(rescaled[mask]))\n",
    "        w_delta_2 = (max_im_width-w)/2\n",
    "        im_final[y_pos:y_pos + h , x_pos+int(w_delta_2):x_pos+int(w_delta_2)+w] = rescaled\n",
    "        x_pos = x_pos + max_im_width\n",
    "    y_pos = y_pos + h\n",
    "\n",
    "# im_final[im_final!=0] = im_final[im_final!=0] - np.min(im_final)\n",
    "\n",
    "seaim.imgplot(im_final, cmap=\"Greys\", dx=25, units=\"um\")\n",
    "# plt.savefig(\"IV_B.png\", dpi=350)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "912973bc544188fb59af9639e4306086aa2fde6767f1a4eaf422201d5f5eefec"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
